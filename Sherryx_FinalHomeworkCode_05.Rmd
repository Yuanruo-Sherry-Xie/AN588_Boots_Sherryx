---
title: "Sherryx_FinalHomeworkCode_05"
author: "Sherry Xie"
date: "2025-04-14"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
    toc: true
---

## Set up

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#loading ggplot for the figures
library(ggplot2)
library(tidyverse)
library(curl)


#loading prettydoc for the theme
library(prettydoc)
```

## [1] Using the ‚ÄúKamilarAndCooperData.csv‚Äù dataset, run a linear regression looking at log(HomeRange_km2) in relation to log(Body_mass_female_mean) and report your ùõΩ coeffiecients (slope and intercept).

```{r}
#Load data
kamilar_cooper <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/refs/heads/master/AN588_Spring25/KamilarAndCooperData.csv")

#fill in blank as N/A
kamilar_cooper <- read.csv(kamilar_cooper, header = TRUE, sep = ",", stringsAsFactors = FALSE)

#show what the data looks like
head(kamilar_cooper)
```

```{r}
#Create new columns in the data set: log(HomeRange) and log(Body Mass)
kamilar_cooper <- kamilar_cooper %>%
  mutate(
    log_HR = log(HomeRange_km2),
    log_BM = log(Body_mass_female_mean)
  ) 

# Fit linear model: log(HomeRange) ~ log(Body Mass)
lm_logHR_logBM <- lm(log_HR ~ log_BM, data = kamilar_cooper)

# Show regression summary
summary(lm_logHR_logBM)

# Show specifically the beta values of intercept and slope
coef(lm_logHR_logBM)
```

## [2] Then, use bootstrapping to sample from your data 1000 times with replacement, each time fitting the same model and calculating the same coefficients. This generates a sampling distribution for each ùõΩ coefficient.

### Estimate the standard error for each of your ùõΩ coefficients as the standard deviation of the sampling distribution from your bootstrap and determine the 95% CI for each of your ùõΩ coefficients based on the appropriate quantiles from your sampling distribution.

```{r}
# Set seed for reproducibility
set.seed(2025)

# Number of bootstrap replicates stated in the instructions 
n_boot <- 1000

# Prepare storage for coefficients
boot_coefs <- matrix(NA, nrow = n_boot, ncol = 2)

# Bootstrap loop
for (i in 1:n_boot) {
  sample_data <- kamilar_cooper[sample(1:nrow(kamilar_cooper), replace = TRUE), ]
  model <- lm(log_HR ~ log_BM, data = sample_data)
  boot_coefs[i, ] <- coef(model)
}

# Convert to dataframe so it will recoginze and run it 
boot_coefs_df <- as.data.frame(boot_coefs)
colnames(boot_coefs_df) <- c("Intercept", "Slope")
```

### How does the former compare to the SE estimated from your entire dataset using the formula for standard error implemented in `lm()`?

```{r}
# Estimate bootstrap standard errors
boot_se <- apply(boot_coefs_df, 2, sd)
boot_se

# Estimate 95% confidence intervals from bootstrap
boot_ci <- apply(boot_coefs_df, 2, quantile, probs = c(0.025, 0.975))
boot_ci

```

### How does the latter compare to the 95% CI estimated from your entire dataset?

```{r}
#UPDATED CODE
# Linear model-based SEs and CIs
lm_summary <- summary(lm_logHR_logBM)
lm_se <- lm_summary$coefficients[, "Std. Error"]
lm_ci <- confint(lm_logHR_logBM)

# Combine into one table
comparison_df <- data.frame(
  Coefficient = c("Intercept", "Slope"),
  Model_SE = round(lm_se, 4),
  Model_CI_Lower = round(lm_ci[,1], 4),
  Model_CI_Upper = round(lm_ci[,2], 4),
  Bootstrap_SE = round(boot_se, 4),
  Bootstrap_CI_Lower = round(boot_ci[1,], 4),
  Bootstrap_CI_Upper = round(boot_ci[2,], 4)
)
print(comparison_df)

```

## EXTRA CREDIT: Write a FUNCTION that takes as its arguments a dataframe, ‚Äúd‚Äù, a linear model, ‚Äúm‚Äù (as a character string, e.g., ‚ÄúlogHR\~logBM‚Äù), a user-defined confidence interval level, ‚Äúconf.level‚Äù (with default = 0.95), and a number of bootstrap replicates, ‚Äún‚Äù (with default = 1000). Your function should return a dataframe that includes: beta coefficient names; beta coefficients, standard errors, and upper and lower CI limits for the linear model based on your entire dataset; and mean beta coefficient estimates, SEs, and CI limits for those coefficients based on your bootstrap.

```{r}
# Extra Credit Function
bootstrap_lm_summary <- function(d, m, conf.level = 0.95, n = 1000) {
  # Convert model string to formula
  model_formula <- as.formula(m)
  
  # Fit model to full dataset
  full_model <- lm(model_formula, data = d)
  coef_names <- names(coef(full_model))
  
  # Extract model-based estimates, SEs, and CIs
  full_estimates <- coef(full_model)
  full_se <- summary(full_model)$coefficients[, "Std. Error"]
  full_ci <- confint(full_model, level = conf.level)
  
  # Bootstrapping
  set.seed(2025)
  boot_coefs <- replicate(n, {
    sample_rows <- d[sample(nrow(d), replace = TRUE), ]
    coef(lm(model_formula, data = sample_rows))
  })
  
  boot_coefs <- t(boot_coefs)
  boot_mean <- apply(boot_coefs, 2, mean)
  boot_se <- apply(boot_coefs, 2, sd)
  boot_ci <- apply(boot_coefs, 2, quantile, probs = c((1 - conf.level)/2, 1 - (1 - conf.level)/2))
  
  # Combine everything into a summary dataframe
  result_df <- data.frame(
    Coefficient = coef_names,
    FullModel_Estimate = round(full_estimates, 4),
    FullModel_SE = round(full_se, 4),
    FullModel_CI_Lower = round(full_ci[, 1], 4),
    FullModel_CI_Upper = round(full_ci[, 2], 4),
    Boot_Estimate = round(boot_mean, 4),
    Boot_SE = round(boot_se, 4),
    Boot_CI_Lower = round(boot_ci[1, ], 4),
    Boot_CI_Upper = round(boot_ci[2, ], 4)
  )
  
  return(result_df)
}


#T.Z: Really liked that you used the replicate function instead of creating a for loop when creating this function because it allowed for a cleaner code.
```

## EXTRA EXTRA CREDIT: Graph each beta value from the linear model and its corresponding mean value, lower CI and upper CI from a bootstrap as a function of number of bootstraps from 10 to 200 by 10s. HINT: the beta value from the linear model will be the same for all bootstraps and the mean beta value may not differ that much!

```{r}
# Create vector of bootstrap sizes from 10 to 200 by 10
boot_sizes <- seq(10, 200, by = 10)

# Empty dataframe to store results
bootstrap_trace <- data.frame()

for (n in boot_sizes) {
  result <- bootstrap_lm_summary(kamilar_cooper, "log_HR ~ log_BM", n = n)
  slope_row <- result[result$Coefficient == "log_BM", ]
  
  bootstrap_trace <- rbind(bootstrap_trace, data.frame(
    n_boot = n,
    mean_slope = slope_row$Boot_Estimate,
    ci_lower = slope_row$Boot_CI_Lower,
    ci_upper = slope_row$Boot_CI_Upper
  ))
}

# Original slope from the full model
original_slope <- coef(lm_logHR_logBM)["log_BM"]

# T.Z: you already loaded this in the beginning!
# Plotting the results
library(ggplot2)

ggplot(bootstrap_trace, aes(x = n_boot)) +
  geom_line(aes(y = mean_slope), color = "blue", size = 1.2) +
  geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper), fill = "skyblue", alpha = 0.3) +
  geom_hline(yintercept = original_slope, linetype = "dashed", color = "red") +
  labs(
    title = "Stability of Bootstrap Estimates for Slope (log_BM)",
    subtitle = "With Increasing Number of Bootstrap Samples",
    x = "Number of Bootstraps",
    y = "Estimated Slope"
  ) +
  theme_minimal()
```

## 5 Struggles I Have Encountered Doing HW 5

1.  **Too Many Inconsistent Variable Names.** One major issue I faced was the lack of consistency in naming my variables. I used similar but slightly different names like boot_ci, bootstrap_ci_upper, and Boot_CI_Upper, with varying cases and underscores. This made it really difficult to remember which variable I had already created and what exactly I called it. As a result, my code wouldn't knit multiple times due to ‚Äúobject not found‚Äù errors, and I had to keep scrolling back to find and match the exact variable names. This taught me the importance of sticking to consistent naming conventions.

2.  **Understanding the Extra Credit Function Requirement.** At first, I found the instructions for the extra credit function a bit confusing. I wasn‚Äôt sure how to structure a function that could flexibly take in a dataset, model string, confidence level, and number of bootstraps. After re-reading the prompt several times, I was able to break it down and design a custom function called bootstrap_lm_summary(). This function accepts a data frame and model formula as arguments, fits the linear model, performs bootstrapping, and returns a summary data frame that includes both the original model's estimates and the bootstrapped statistics (means, SEs, CIs). It ended up being one of the most useful pieces of code I wrote in this assignment.

3.  **Helping a Peer Without Giving Away the Answer.** My peer review partner didn‚Äôt complete the extra credit sections, so I tried to give her encouragement and a bit of guidance on how to get started without directly giving away the solution. It was actually very difficult to explain the logic behind the function without showing the actual code. This experience helped me realize how tricky it can be to teach or explain code to others‚Äîeven if you understand it yourself‚Äîbecause you have to think through every step and anticipate where someone else might get confused.

4.  **Rewriting Instead of Reusing My Own Code.** The extra extra credit question was even more challenging. I initially didn‚Äôt realize that I could reuse my bootstrap_lm_summary() function from the extra credit section. Instead, I wasted time rewriting a new process for each bootstrap size from scratch. Luckily, my peer Tiffany gave me the suggestion to reuse my existing function, which made everything so much simpler and more elegant. It really clicked for me at that moment how important it is to write reusable code and avoid unnecessary repetition.

5.  **Creating a Visually Clear and Informative Graph.** For the extra extra credit, I struggled with how to make a graph that was both visually clear and informative. I wanted to show the stability of the bootstrapped estimates over increasing sample sizes while also comparing them to the original model. I wasn't sure whether to use a single plot with annotations, or two separate side-by-side plots for better comparison. In the end, I created one plot showing the bootstrapped mean slope, CI bounds, and the original slope as a dashed line. I think it worked okay, but in the future I‚Äôd like to improve my ggplot skills to make even clearer visual comparisons‚Äîperhaps using facet plots or side-by-side panels for better storytelling.
